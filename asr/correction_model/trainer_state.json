{
  "best_metric": 0.012998213991522789,
  "best_model_checkpoint": "./results_simple/checkpoint-8000",
  "epoch": 2.962962962962963,
  "eval_steps": 1000,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07407407407407407,
      "grad_norm": 0.2048354148864746,
      "learning_rate": 4.876543209876544e-05,
      "loss": 0.0242,
      "step": 200
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 0.15547195076942444,
      "learning_rate": 4.7530864197530866e-05,
      "loss": 0.03,
      "step": 400
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.06611871719360352,
      "learning_rate": 4.62962962962963e-05,
      "loss": 0.0257,
      "step": 600
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 0.01336024422198534,
      "learning_rate": 4.506172839506173e-05,
      "loss": 0.0166,
      "step": 800
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.10492995381355286,
      "learning_rate": 4.3827160493827164e-05,
      "loss": 0.0229,
      "step": 1000
    },
    {
      "epoch": 0.37037037037037035,
      "eval_loss": 0.018899012356996536,
      "eval_runtime": 32.3229,
      "eval_samples_per_second": 83.532,
      "eval_steps_per_second": 10.457,
      "step": 1000
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 2.776682138442993,
      "learning_rate": 4.259259259259259e-05,
      "loss": 0.0192,
      "step": 1200
    },
    {
      "epoch": 0.5185185185185185,
      "grad_norm": 0.004986768588423729,
      "learning_rate": 4.135802469135803e-05,
      "loss": 0.0234,
      "step": 1400
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 0.0892183855175972,
      "learning_rate": 4.012345679012346e-05,
      "loss": 0.0219,
      "step": 1600
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.02555384486913681,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.0154,
      "step": 1800
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 1.2494715452194214,
      "learning_rate": 3.7654320987654326e-05,
      "loss": 0.0219,
      "step": 2000
    },
    {
      "epoch": 0.7407407407407407,
      "eval_loss": 0.017807181924581528,
      "eval_runtime": 32.3525,
      "eval_samples_per_second": 83.456,
      "eval_steps_per_second": 10.447,
      "step": 2000
    },
    {
      "epoch": 0.8148148148148148,
      "grad_norm": 0.005174660123884678,
      "learning_rate": 3.6419753086419754e-05,
      "loss": 0.0194,
      "step": 2200
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.5392504930496216,
      "learning_rate": 3.518518518518519e-05,
      "loss": 0.0212,
      "step": 2400
    },
    {
      "epoch": 0.9629629629629629,
      "grad_norm": 1.7941534519195557,
      "learning_rate": 3.395061728395062e-05,
      "loss": 0.0201,
      "step": 2600
    },
    {
      "epoch": 1.037037037037037,
      "grad_norm": 1.803764820098877,
      "learning_rate": 3.271604938271605e-05,
      "loss": 0.0134,
      "step": 2800
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.34035012125968933,
      "learning_rate": 3.148148148148148e-05,
      "loss": 0.0081,
      "step": 3000
    },
    {
      "epoch": 1.1111111111111112,
      "eval_loss": 0.0158757995814085,
      "eval_runtime": 32.4501,
      "eval_samples_per_second": 83.205,
      "eval_steps_per_second": 10.416,
      "step": 3000
    },
    {
      "epoch": 1.1851851851851851,
      "grad_norm": 1.8799948692321777,
      "learning_rate": 3.0246913580246916e-05,
      "loss": 0.0113,
      "step": 3200
    },
    {
      "epoch": 1.2592592592592593,
      "grad_norm": 0.01721816323697567,
      "learning_rate": 2.9012345679012347e-05,
      "loss": 0.0143,
      "step": 3400
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.45164161920547485,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.0098,
      "step": 3600
    },
    {
      "epoch": 1.4074074074074074,
      "grad_norm": 0.02593175508081913,
      "learning_rate": 2.654320987654321e-05,
      "loss": 0.0096,
      "step": 3800
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 0.06764356791973114,
      "learning_rate": 2.5308641975308646e-05,
      "loss": 0.0139,
      "step": 4000
    },
    {
      "epoch": 1.4814814814814814,
      "eval_loss": 0.015172670595347881,
      "eval_runtime": 32.5506,
      "eval_samples_per_second": 82.948,
      "eval_steps_per_second": 10.384,
      "step": 4000
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.290275901556015,
      "learning_rate": 2.4074074074074074e-05,
      "loss": 0.0105,
      "step": 4200
    },
    {
      "epoch": 1.6296296296296298,
      "grad_norm": 2.4738242626190186,
      "learning_rate": 2.2839506172839506e-05,
      "loss": 0.0132,
      "step": 4400
    },
    {
      "epoch": 1.7037037037037037,
      "grad_norm": 0.1751958280801773,
      "learning_rate": 2.1604938271604937e-05,
      "loss": 0.0132,
      "step": 4600
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.07835257798433304,
      "learning_rate": 2.037037037037037e-05,
      "loss": 0.0105,
      "step": 4800
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.0024193446151912212,
      "learning_rate": 1.91358024691358e-05,
      "loss": 0.0105,
      "step": 5000
    },
    {
      "epoch": 1.8518518518518519,
      "eval_loss": 0.013661143369972706,
      "eval_runtime": 32.4133,
      "eval_samples_per_second": 83.299,
      "eval_steps_per_second": 10.428,
      "step": 5000
    },
    {
      "epoch": 1.925925925925926,
      "grad_norm": 2.656214952468872,
      "learning_rate": 1.7901234567901236e-05,
      "loss": 0.0069,
      "step": 5200
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.104642391204834,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0098,
      "step": 5400
    },
    {
      "epoch": 2.074074074074074,
      "grad_norm": 0.011179710738360882,
      "learning_rate": 1.54320987654321e-05,
      "loss": 0.0057,
      "step": 5600
    },
    {
      "epoch": 2.148148148148148,
      "grad_norm": 0.21890142560005188,
      "learning_rate": 1.419753086419753e-05,
      "loss": 0.0038,
      "step": 5800
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.0013630385510623455,
      "learning_rate": 1.2962962962962962e-05,
      "loss": 0.0048,
      "step": 6000
    },
    {
      "epoch": 2.2222222222222223,
      "eval_loss": 0.014430149458348751,
      "eval_runtime": 32.3679,
      "eval_samples_per_second": 83.416,
      "eval_steps_per_second": 10.442,
      "step": 6000
    },
    {
      "epoch": 2.2962962962962963,
      "grad_norm": 0.012989871203899384,
      "learning_rate": 1.1728395061728396e-05,
      "loss": 0.0076,
      "step": 6200
    },
    {
      "epoch": 2.3703703703703702,
      "grad_norm": 0.007484277244657278,
      "learning_rate": 1.0493827160493827e-05,
      "loss": 0.0068,
      "step": 6400
    },
    {
      "epoch": 2.4444444444444446,
      "grad_norm": 0.04371797665953636,
      "learning_rate": 9.259259259259259e-06,
      "loss": 0.0068,
      "step": 6600
    },
    {
      "epoch": 2.5185185185185186,
      "grad_norm": 0.0030298372730612755,
      "learning_rate": 8.02469135802469e-06,
      "loss": 0.0074,
      "step": 6800
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 0.00209465017542243,
      "learning_rate": 6.790123456790123e-06,
      "loss": 0.0056,
      "step": 7000
    },
    {
      "epoch": 2.5925925925925926,
      "eval_loss": 0.014043700881302357,
      "eval_runtime": 32.3362,
      "eval_samples_per_second": 83.498,
      "eval_steps_per_second": 10.453,
      "step": 7000
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.010314811021089554,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.0065,
      "step": 7200
    },
    {
      "epoch": 2.7407407407407405,
      "grad_norm": 0.0011703944765031338,
      "learning_rate": 4.3209876543209875e-06,
      "loss": 0.0064,
      "step": 7400
    },
    {
      "epoch": 2.814814814814815,
      "grad_norm": 0.006569028366357088,
      "learning_rate": 3.0864197530864196e-06,
      "loss": 0.008,
      "step": 7600
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.011608763597905636,
      "learning_rate": 1.8518518518518519e-06,
      "loss": 0.0057,
      "step": 7800
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 0.003237678436562419,
      "learning_rate": 6.17283950617284e-07,
      "loss": 0.0035,
      "step": 8000
    },
    {
      "epoch": 2.962962962962963,
      "eval_loss": 0.012998213991522789,
      "eval_runtime": 32.539,
      "eval_samples_per_second": 82.977,
      "eval_steps_per_second": 10.388,
      "step": 8000
    }
  ],
  "logging_steps": 200,
  "max_steps": 8100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1905426432000000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
